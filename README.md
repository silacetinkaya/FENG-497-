<body>

  <h1>Computer-Aided Detection of Colorectal Polyps</h1>

  <p>
    This repository contains a prototype <strong>Computer-Aided Detection (CADe)</strong> system 
    designed to automatically detect and segment colorectal polyps in colonoscopy images using 
    a deep learningâ€“based <strong>UNet segmentation model</strong>.
  </p>

  <hr />

  <h2>âœ¨ Features</h2>
  <ul>
    <li>Automatic segmentation of polyp regions in colonoscopy frames</li>
    <li>Deep learningâ€“based UNet architecture with ResNet34 encoder</li>
    <li>Support for training, validation, and inference</li>
    <li>Overlay generation: masks applied to original frames</li>
    <li>Modular and clean code structure (datasets, models, utils, inference)</li>
  </ul>

  <h2>ğŸ§± Tech Stack</h2>
  <ul>
    <li><strong>Language:</strong> Python</li>
    <li><strong>Framework:</strong> PyTorch</li>
    <li><strong>Image Processing:</strong> OpenCV</li>
    <li><strong>Visualization:</strong> Matplotlib / NumPy</li>
  </ul>

  <hr />

  <h2>ğŸ“‚ Dataset</h2>
  <p>
    This project uses the <strong>Kvasir-SEG</strong> dataset, which contains 1000 polyp images and ground-truth masks.
    Download link:
  </p>

  <p>
    ğŸ”— <a href="https://datasets.simula.no/kvasir-seg/">https://datasets.simula.no/kvasir-seg/</a>
  </p>

  <p><strong>Dataset is NOT included in this repository</strong> due to size constraints. 
     After downloading, place the dataset into the following structure:</p>

  <pre>
  data/kvasir/
    â”œâ”€â”€ images/   (1000 colonoscopy images)
    â””â”€â”€ masks/    (1000 segmentation masks)
  </pre>

  <hr />

  <h2>ğŸš€ Getting Started</h2>

  <h3>1ï¸âƒ£ Install Dependencies</h3>
  <pre><code>pip install -r requirements.txt</code></pre>

  <h3>2ï¸âƒ£ Prepare Dataset</h3>
  <p>Download Kvasir-SEG and place the images/masks into:</p>
  <pre>data/kvasir/images/
data/kvasir/masks/</pre>

  <h3>3ï¸âƒ£ Train the Model</h3>
  <pre><code>python train.py</code></pre>

  <p>The trained UNet model will be saved as:</p>
  <pre>models/unet_polyp.pth</pre>

  <h3>4ï¸âƒ£ Run Inference</h3>
  <pre><code>python infer.py</code></pre>

  <p>
    This will load the model and generate an overlay image highlighting the detected polyp regions.
    The output file:
  </p>
  <pre>overlay_result.png</pre>

  <hr />

  <h2>ğŸ“Š Evaluation</h2>
  <p>
    The model can be evaluated through common segmentation metrics:
  </p>
  <ul>
    <li>Dice Coefficient</li>
    <li>Intersection over Union (IoU)</li>
    <li>Precision / Recall</li>
    <li>Binary Cross-Entropy Loss</li>
  </ul>

  <hr />

  <h2>ğŸ§­ Roadmap</h2>
  <ul>
    <li>âœ… Trainable UNet segmentation pipeline</li>
    <li>âœ… Inference + overlay visualization</li>
    <li>â¬œ Add evaluation metrics and validation pipeline</li>
    <li>â¬œ Real-time video segmentation</li>
    <li>â¬œ Convert model to TFLite for mobile deployment (Flutter app)</li>
    <li>â¬œ Hyperparameter tuning and more advanced architectures</li>
  </ul>

  <hr />

  <h2>ğŸ“Œ Notes</h2>
  <ul>
    <li>Dataset and trained weights are excluded due to size limitations.</li>
    <li>Model can be retrained with <code>train.py</code>.</li>
    <li>The project is structured to make future expansion into mobile apps easy.</li>
  </ul>

</body>
</html>
